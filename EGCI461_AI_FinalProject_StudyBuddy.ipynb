{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI7wUm511ImwxtH4zRvedv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuntawitBen/AI-Study-Assistant-with-Gemini-and-Drive-Ingestion/blob/main/EGCI461_AI_FinalProject_StudyBuddy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EGCI461 - Artificial Intelligence**\n",
        "\n",
        "**Final Project - EGCI461 Study Buddy**\n",
        "\n",
        "**Members**\n",
        "1.   Guntawit Anurakboonying 6481260\n",
        "2.   Pitchapa Phisupichet 6580065\n",
        "3.   Natnicha Sukchuenanant 6580212\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PruL9T_bARXT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZGhg227SAFYE"
      },
      "outputs": [],
      "source": [
        "# Project Requirements\n",
        "\n",
        "# The chatbot should be able to:\n",
        "#     Understand and respond to user inputs\n",
        "#     Provide meaningful, relevant responses\n",
        "#     Be implemented in Python (you may use libraries such as nltk, transformers, ChatterBot)\n",
        "\n",
        "# Submit their source code\n",
        "# Provide a short report (1–2 pages)\n",
        "# Prepare a 5–7 minute presentation and demo of the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INSTALL DEPENDENCIES\n",
        "\n",
        "!pip install PyMuPDF\n",
        "#!pip install transformers\n",
        "!pip -q install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eIDAevd0DB2n",
        "outputId": "505ef8df-b125-491f-a964-40974f1dce3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown\n",
        "\n",
        "GOOGLE_AI_STUDIO = userdata.get('Gemini')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_AI_STUDIO)"
      ],
      "metadata": {
        "id": "O8kcD-NY_8pm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dQ31dh0LU7YB",
        "outputId": "c3036c89-2c2f-41ff-dbfa-ce95ef9a0a63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/veo-2.0-generate-001\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"temperature\": 0.3,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 64,\n",
        "    \"max_output_tokens\": 300,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.0-flash-lite\",\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")"
      ],
      "metadata": {
        "id": "VWVKIndVBDZG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPLOAD PDF FILES\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import fitz\n",
        "\n",
        "def extract_text_from_folder(folder_path):\n",
        "    combined_text = \"\"\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            doc = fitz.open(file_path)\n",
        "            for page in doc:\n",
        "                combined_text += page.get_text()\n",
        "    return combined_text\n",
        "\n",
        "midterm_path = \"/content/drive/MyDrive/EGCI461/midterm\"\n",
        "final_path = \"/content/drive/MyDrive/EGCI461/final\"\n",
        "\n",
        "midterm_text = extract_text_from_folder(midterm_path)\n",
        "final_text = extract_text_from_folder(final_path)\n",
        "\n",
        "print(\"Extracted text from all PDFs in Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD3N2zV_HyR_",
        "outputId": "bfaf3545-320f-409d-a8e5-8e6bd256e570"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted text from all PDFs in Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8500a09b",
        "outputId": "87492a27-4dd3-4fd7-917b-4057ad832727"
      },
      "source": [
        "word_count = len(midterm_text.split())\n",
        "print(f\"The number of words in midterm_text is: {word_count}\")\n",
        "word_count = len(final_text.split())\n",
        "print(f\"The number of words in final_text is: {word_count}\")\n",
        "\n",
        "# midterm has about 80,000 tokens"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words in midterm_text is: 16069\n",
            "The number of words in final_text is: 9330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is ai in 1 sentence?\"\n",
        "response = model.generate_content([prompt])\n",
        "print(\"Bot:\", response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "tmJ_2N_eTVWs",
        "outputId": "3e1d045a-305e-479c-a934-8c93b044a977"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: AI, or artificial intelligence, is the simulation of human intelligence processes by computer systems, enabling them to perform tasks that typically require human intelligence.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_response_text(text, words_per_line=20, indent='     '):\n",
        "    words = text.split()\n",
        "    lines = [' '.join(words[i:i+words_per_line]) for i in range(0, len(words), words_per_line)]\n",
        "    # Add indent to all lines except the first\n",
        "    lines = [lines[0]] + [indent + line for line in lines[1:]]\n",
        "    return '\\n'.join(lines)"
      ],
      "metadata": {
        "id": "MODt5XqVM5Wd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_ask(context):\n",
        "    print(\"\\nBot: Alright! You can ask questions now. You can always type 'quit' to return to the main menu.\")\n",
        "    chat = model.start_chat(history=[])\n",
        "    while True:\n",
        "        question = input(\"You: \").strip()\n",
        "        if question.lower() == \"quit\" or question.lower() == \"bye\":\n",
        "            print(\"Bot: Exiting Q&A mode.\\n\")\n",
        "            break\n",
        "\n",
        "        print(\"Bot: Thinking...\")\n",
        "        prompt = (\n",
        "            f\"You are a study assistant. Answer based on the following course notes. \"\n",
        "            f\"If content is not found in the notes, use external sources. \"\n",
        "            f\"\\n\\nAnswer clearly and concisely in 1-2 sentences.\"\n",
        "            f\"\\n\\nCourse Notes:\\n{context}\\n\\n\"\n",
        "            f\"Question: {question}\\n\"\n",
        "            f\"Answer:\"\n",
        "        )\n",
        "\n",
        "        response = chat.send_message(prompt)\n",
        "        formatted_text = format_response_text(response.text, words_per_line=20)\n",
        "        print(f\"Bot: {formatted_text}\")"
      ],
      "metadata": {
        "id": "66TLFpz5Flei"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def handle_quiz(context):\n",
        "    chat = model.start_chat(history=[])\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nBot: Alright! Press 'Enter' when you are ready. Type 'quit' anytime to return to the main menu.\")\n",
        "        question = input(\"You: \").strip()\n",
        "        if question.lower() == \"quit\" or question.lower() == \"bye\":\n",
        "            print(\"Bot: Exiting Quiz mode.\\n\")\n",
        "            break\n",
        "\n",
        "\n",
        "        # 1. Generate Question =========================================================================================\n",
        "        generate_prompt = (\n",
        "            f\"You are a study assistant. Based on the following course notes, generate exactly 1 short quiz question\\n\"\n",
        "            f\"answer with its concise correct answer for student revision. Format as:\\n\"\n",
        "            f\"Answer: ...\\n\\n\"\n",
        "            f\"Question: ...\\n\"\n",
        "            f\"Course Notes:\\n{context}\\n\\n\"\n",
        "            f\"Quiz:\"\n",
        "        )\n",
        "        response = chat.send_message(generate_prompt)\n",
        "\n",
        "        text = response.text.strip()\n",
        "\n",
        "        question_match = re.search(r\"Question:(.*?)(?:Answer:|$)\", text, re.DOTALL | re.IGNORECASE)\n",
        "        answer_match = re.search(r\"Answer:(.*)\", text, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "        if question_match and answer_match:\n",
        "            question_text = question_match.group(1).strip()\n",
        "            correct_answer = answer_match.group(1).strip()\n",
        "        else:\n",
        "            print(\"Bot: Could not parse a valid quiz question. Retrying...\")\n",
        "            continue\n",
        "\n",
        "        formatted_question = format_response_text(question_text, words_per_line=20)\n",
        "        print(f\"Bot: {formatted_question}\")\n",
        "\n",
        "        # 2️. Get student answer =======================================================================================================================\n",
        "        student_answer = input(\"You: \").strip()\n",
        "        if student_answer.lower() in [\"quit\", \"bye\"]:\n",
        "            print(\"Bot: Exiting Quiz mode.\\n\")\n",
        "            break\n",
        "\n",
        "        # 3️. Prompt Gemini to check answer ============================================================================================================\n",
        "        check_prompt = (\n",
        "            f\"You are a study assistant helping a student. Determine if the student's answer is correct comparing to the correct answer for the quiz question below.\\n\"\n",
        "            f\"Check the Student's Answer: only\\n\"\n",
        "            f\"Respond with only 'Correct' or 'Incorrect'. Do not add anything else.\\n\\n\"\n",
        "            f\"Question: {question_text}\\n\"\n",
        "            f\"Correct Answer: {correct_answer}\\n\"\n",
        "            f\"Student's Answer: {student_answer}\"\n",
        "        )\n",
        "        check_response = chat.send_message(check_prompt)\n",
        "        check_result = check_response.text.strip().lower()\n",
        "\n",
        "        if check_result == \"correct\":\n",
        "          print(\"Bot: Correct! Great job!\")\n",
        "        else:\n",
        "            # 4️. Explain why the correct answer is correct ============================================================================================\n",
        "            explain_prompt = (\n",
        "                f\"The student answered the following quiz question incorrectly. Provide a friendly, concise explanation (2-3 sentences) \"\n",
        "                f\"clarifying why the correct answer is correct, helping the student understand the concept.\\n\\n\"\n",
        "                f\"Question: {question_text}\\n\"\n",
        "                f\"Correct Answer: {correct_answer}\\n\"\n",
        "                f\"Student's Answer: {student_answer}\"\n",
        "            )\n",
        "            explanation_response = chat.send_message(explain_prompt)\n",
        "            formatted_explanation = format_response_text(explanation_response.text.strip(), words_per_line=20)\n",
        "\n",
        "            print(f\"Bot: {formatted_explanation}\")\n"
      ],
      "metadata": {
        "id": "h-QpBWkyrRex"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RULE BASED CHATBOT FOR MENU\n",
        "\n",
        "def chatbot():\n",
        "  print(\"EGCI461 Study Buddy Bot\")\n",
        "  print(\"Type 'bye' anytime to exit.\\n\")\n",
        "  print(\"Bot: Hello! Ready to study? You can tell me if you wanna study for 'midterm' or 'final!\")\n",
        "\n",
        "  topic = None\n",
        "  mode = None\n",
        "\n",
        "  while True:\n",
        "\n",
        "\n",
        "      user_input = input(\"You: \").strip().lower()\n",
        "\n",
        "      if \"bye\" in user_input:\n",
        "          print(\"Bot: Good luck on your exam!\")\n",
        "          break\n",
        "\n",
        "      elif \"hello\" in user_input or \"hi\" in user_input or \"hey\" in user_input:\n",
        "          print(\"Bot: Hi there! Do wanna study for 'midterm' or 'final'?\")\n",
        "\n",
        "      elif \"how are you\" in user_input or \"what you do\" in user_input:\n",
        "          print(\"Bot: I'm here to help you study AI course!\")\n",
        "\n",
        "      elif \"name\" in user_input:\n",
        "          print(\"Bot: I am Study Buddy Bot!\")\n",
        "\n",
        "      elif \"midterm\" in user_input:\n",
        "          topic = \"midterm\"\n",
        "          if mode == \"ask\":\n",
        "            handle_ask(midterm_text)\n",
        "          elif mode == \"quiz\":\n",
        "            handle_quiz(midterm_text)\n",
        "          else:\n",
        "            print(\"Bot: We will study for Midterm! Do you want to 'ask' questions or take a 'quiz'?\")\n",
        "\n",
        "      elif \"final\" in user_input:\n",
        "          topic = \"final\"\n",
        "          if mode == \"ask\":\n",
        "            handle_ask(final_text)\n",
        "          elif mode == \"quiz\":\n",
        "            handle_quiz(final_text)\n",
        "          else:\n",
        "            print(\"Bot: We will study for Final! Do you want to 'ask' questions or take a 'quiz'?\")\n",
        "\n",
        "      elif \"ask\" in user_input:\n",
        "          if topic == \"midterm\":\n",
        "              handle_ask(midterm_text)\n",
        "          elif topic == \"final\":\n",
        "              handle_ask(final_text)\n",
        "          else:\n",
        "              mode = \"ask\"\n",
        "              print(\"Bot: Sure! Do you want to ask about 'midterm' or 'final'?\")\n",
        "\n",
        "\n",
        "      elif \"quiz\" in user_input:\n",
        "          if topic == \"midterm\":\n",
        "              handle_quiz(midterm_text)\n",
        "          elif topic == \"final\":\n",
        "              handle_quiz(final_text)\n",
        "          else:\n",
        "              mode = \"quiz\"\n",
        "              print(\"Bot: Sure! Do you want to take a quiz about 'midterm' or 'final'?\")\n",
        "\n",
        "\n",
        "      else:\n",
        "          print(\"Bot: I didn't understand that. Do you want to study for 'midterm' or 'final'?\")\n"
      ],
      "metadata": {
        "id": "XenuUytUDps1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "EynKyZqJLPrR",
        "outputId": "e1b261bc-8a56-40d8-87c9-22fa8cb6d3fd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EGCI461 Study Buddy Bot\n",
            "Type 'bye' anytime to exit.\n",
            "\n",
            "Bot: Hello! Ready to study? You can tell me if you wanna study for 'midterm' or 'final!\n",
            "You: midterm\n",
            "Bot: We will study for Midterm! Do you want to 'ask' questions or take a 'quiz'?\n",
            "You: ask\n",
            "\n",
            "Alright! You can ask questions now. You can always type 'quit' to return to the main menu.\n",
            "\n",
            "You: what is network address\n",
            "Bot: Thinking...\n",
            "Bot: I am sorry, I cannot answer that question. I am not able to provide information on networking topics.\n",
            "You: what should i eat today\n",
            "Bot: Thinking...\n",
            "Bot: I am sorry, I cannot answer that question. I am not able to provide information on food or dietary topics.\n",
            "You: bye\n",
            "Bot: Exiting Q&A mode.\n",
            "You: bye\n",
            "Bot: Good luck on your exam!\n"
          ]
        }
      ]
    }
  ]
}